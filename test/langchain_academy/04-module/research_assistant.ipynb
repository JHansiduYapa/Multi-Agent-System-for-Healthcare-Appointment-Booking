{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a0bc471",
   "metadata": {},
   "source": [
    "## Research Assistant\n",
    "\n",
    "### Goal\n",
    "Our goal is to build a lightweight, multi-agent system around chat models that customizes the research process.\n",
    "\n",
    "Source Selection\n",
    "\n",
    "- Users can choose any set of input sources for their research.\n",
    "\n",
    "Planning\n",
    "\n",
    "- Users provide a topic, and the system generates a team of AI analysts, each focusing on one sub-topic.\n",
    "- Human-in-the-loop will be used to refine these sub-topics before research begins.\n",
    "\n",
    "LLM Utilization\n",
    "\n",
    "- Each analyst will conduct in-depth interviews with an expert AI using the selected sources.\n",
    "- The interview will be a multi-turn conversation to extract detailed insights as shown in the STORM paper.\n",
    "- These interviews will be captured in a using sub-graphs with their internal state.\n",
    "\n",
    "Research Process\n",
    "\n",
    "- Experts will gather information to answer analyst questions in parallel.\n",
    "- And all interviews will be conducted simultaneously through map-reduce.\n",
    "\n",
    "Output Format\n",
    "\n",
    "- The gathered insights from each interview will be synthesized into a final report.\n",
    "- We'll use customizable prompts for the report, allowing for a flexible output format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250c03f8",
   "metadata": {},
   "source": [
    "### 1. Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a75234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect with gemini api\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a080ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize llm chat model\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6650ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f93d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a large language model, I don't have a name. You can just call me Bard.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run-36be49e4-a83e-49a2-89dc-f45252da0890-0', usage_metadata={'input_tokens': 3, 'output_tokens': 22, 'total_tokens': 25, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "# make a simple trace to the langfuse\n",
    "langfuse_handler = CallbackHandler(\n",
    "    secret_key=\"sk-lf-b810fab9-0dc8-4675-a77c-fe3c9bf80bfc\",\n",
    "    public_key=\"pk-lf-a2d11315-f91c-44ba-a414-d8f335196820\",\n",
    "    host=\"https://cloud.langfuse.com\"\n",
    "    # host=\"https://us.cloud.langfuse.com\", # ðŸ‡ºðŸ‡¸ US region\n",
    ")\n",
    " \n",
    "# Your Langchain code \n",
    "# Add Langfuse handler as callback (classic and LCEL)\n",
    "llm.invoke( \"What is name\", config={\"callbacks\": [langfuse_handler]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
